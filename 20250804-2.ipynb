{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15db0b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['LANGSMITH_PROJECT']  =\"skn15-1\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4756603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "loader = CSVLoader(file_path=\"./data/아리계곡_통합.csv\")\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e97048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2697"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35e8f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지점명: 강남점\\ndate: 2025년 7월 22일 화요일\\nnickname: 임구임구\\nreview_content: 닭을 샤브샤브처럼 먹는것도 새롭고 메뉴가 다 맛있어서 이것저것 엄청 먹어봤어요!소곱창순두부전걸도 맛있었는데 흡입하니라 사진이 없는정도 ㅋㅋㅋ강남 술 모임 하실때 아주 괜찮습니다👍🏻👍🏻더보기\\nwait_time: 바로 입장'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "193d1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cc55dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(docs, embedding = embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7133e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc8a310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "다음 문맥만을 고려해 질문에 답하세요.\n",
    "\n",
    "문맥: \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "질문: {question}\n",
    "''')\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": retriever,\n",
    "} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99bf0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke(\"분위기가 어두운 편인가?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a059efdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('문맥에 따르면, 리뷰에서 \"분위기 넘 좋고\", \"분위기도 좋고 데이트하기 너무 좋아요!\"와 같은 긍정적인 표현이 사용되고 있습니다. '\n",
      " '하지만 \"분위기가 어둡다\"는 직접적인 언급이나 어두운 분위기를 암시하는 내용은 없습니다. 오히려 친구들과 좋은 시간을 보내거나 데이트하기 '\n",
      " '좋다는 점에서 밝고 쾌적한 분위기임을 시사합니다.\\n'\n",
      " '\\n'\n",
      " '따라서, 문맥만을 고려할 때 **분위기가 어두운 편이라고 볼 근거는 없습니다**.')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89c93c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class QueryGenerationOutput(BaseModel):\n",
    "    queries: list[str] = Field(..., description=\"검색 쿼리 목록\")\n",
    "\n",
    "\n",
    "query_generation_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "질문에 대해 벡터 데이터베이스에서 관련 문서를 검색하기 위한\n",
    "3개의 서로 다른 검색 쿼리를 생성하세요.\n",
    "거리 기반 유사성 검색의 한계를 극복하기 위해\n",
    "사용자의 질문에 대해 여러 관점을 제공하는 것이 목표입니다.\n",
    "\n",
    "질문: {question}\n",
    "\"\"\")\n",
    "\n",
    "query_generation_chain = (\n",
    "    query_generation_prompt\n",
    "    | model.with_structured_output(QueryGenerationOutput)\n",
    "    | (lambda x: x.queries)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58bad4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_rag_chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": query_generation_chain | retriever.map(),\n",
    "} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0013eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = multi_query_rag_chain.invoke(\"주위사람에게 추천할 여부?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59056a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('문맥에 따르면, 여러 리뷰에서 \"친구들이랑 오기 좋을 것 같아요\", \"지인추천으로 한번 왔다가\", \"건대오시면 강력추천드립니다\" 등 '\n",
      " '주위사람에게 추천하거나 추천받았다는 내용이 반복적으로 언급되고 있습니다. 따라서, 주위사람에게 추천할 만하다고 볼 수 있습니다.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b87aff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LANGCHAIN_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a4ff200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion( retriever_outputs: list[list[Document]],  k: int = 60 ) -> list[str]:\n",
    "    # 각 문서의 콘텐츠(문자열)와 그 점수의 매핑을 저장하는 딕셔너리 준비\n",
    "    content_score_mapping = {}\n",
    "\n",
    "    # 검색 쿼리마다 반복\n",
    "    for docs in retriever_outputs:\n",
    "        # 검색 결과의 문서마다 반복\n",
    "        for rank, doc in enumerate(docs):\n",
    "            content = doc.page_content\n",
    "\n",
    "            # 처음 등장한 콘텐츠인 경우 점수를 0으로 초기화\n",
    "            if content not in content_score_mapping:\n",
    "                content_score_mapping[content] = 0\n",
    "\n",
    "            # (1 / (순위 + k)) 점수를 추가\n",
    "            content_score_mapping[content] += 1 / (rank + k)\n",
    "\n",
    "    # 점수가 큰 순서로 정렬\n",
    "    ranked = sorted(content_score_mapping.items(), key=lambda x: x[1], reverse=True)  # noqa\n",
    "    return [content for content, _ in ranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce6a2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_fusion_chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": query_generation_chain | retriever.map() | reciprocal_rank_fusion,\n",
    "} | prompt | model | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a4c6b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주어진 문맥에서는 대부분의 리뷰가 매장 분위기, 인테리어, 메뉴, 직원 친절도 등 긍정적인 평가를 하고 있습니다. 또한 \"바로 입장\" 또는 \"10분 이내\" 등 대기 시간도 짧은 편입니다. 다만, 종각점에서 \"30분 이내\" 대기 시간이 언급된 점을 볼 때, 일부 시간대나 지점(특히 종각점)에서는 대기 시간이 다소 길어질 수 있습니다.\\n\\n따라서, 문맥만을 고려할 때 가게에서 개선해야 할 점은 **일부 지점(특히 종각점)의 대기 시간 관리**입니다.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_fusion_chain.invoke(\"가게에서 개선해야 하는 것은?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44d49369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65083748",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_document_retriever = retriever.with_config({'run_name' : 'langchain_document_retriver'})\n",
    "web_retriever = TavilySearchAPIRetriever(k=10).with_config({'run_name' : 'web_retriver'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ccbe0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Route(str, Enum):\n",
    "    langchain_document = 'langchain_document'\n",
    "    web = \"web\"\n",
    "\n",
    "class RouteOutput(BaseModel):\n",
    "    route: Route\n",
    "\n",
    "route_prompt  =  ChatPromptTemplate.from_template(\"\"\"   \n",
    "질문에 답변하기 위한 적절한 Retriever를 선택하세요.\n",
    "\n",
    "질문: {question}\n",
    "\"\"\")\n",
    "\n",
    "route_chain = (\n",
    "    route_prompt | model.with_structured_output(RouteOutput) \n",
    "    | (lambda x : x.route)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08263b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def routed_retriever(inp):\n",
    "    question = inp['question']\n",
    "    route = inp['route']\n",
    "\n",
    "    if route == Route.langchain_document:\n",
    "        return langchain_document_retriever.invoke(question)\n",
    "    elif route == Route.web:\n",
    "        return web_retriever.invoke(question)\n",
    "\n",
    "    raise ValueError(f\"Unkown route: {route}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fe0aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_rag_chain = ({\n",
    "    'question' : RunnablePassthrough(),\n",
    "    \"route\" : route_chain\n",
    "}\n",
    "| RunnablePassthrough.assign(context=routed_retriever)\n",
    "| prompt | model | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5e444e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'문맥에 따르면, **막걸리는 대표적인 전통주(탁주)** 중 하나입니다.  \\n- **탁주**는 빚깔이 탁하고 흐린 술을 말하며, 막걸리가 대표적입니다.\\n- **전통주**는 지역과 원료에 따라 다양한 술을 포함하는 넓은 개념이고, 막걸리는 그중 하나입니다.\\n\\n즉, **막걸리는 전통주(특히 탁주)의 한 종류**이고, 전통주는 막걸리를 포함한 다양한 한국의 전통 술 전체를 의미합니다.  \\n따라서, **전통주와 막걸리의 차이**는  \\n- 전통주는 막걸리를 포함한 모든 한국 전통 술을 의미하고,  \\n- 막걸리는 그중에서 쌀로 빚고 탁한 빛깔을 가진 대표적인 술입니다.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_rag_chain.invoke(\"아리계속에서 전통주와 막걸리 차이가 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e9aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
