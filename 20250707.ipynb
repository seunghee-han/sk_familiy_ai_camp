{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":8008269,"datasetId":3775672,"databundleVersionId":8120113}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"s076923/pytorch-transformer\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:00:25.360920Z","iopub.execute_input":"2025-07-07T05:00:25.361424Z","iopub.status.idle":"2025-07-07T05:00:25.995273Z","shell.execute_reply.started":"2025-07-07T05:00:25.361399Z","shell.execute_reply":"2025-07-07T05:00:25.994499Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/pytorch-transformer\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nfrom PIL import Image\nfrom pycocotools.coco import COCO\nfrom torch.utils.data import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:00:25.996352Z","iopub.execute_input":"2025-07-07T05:00:25.996588Z","iopub.status.idle":"2025-07-07T05:00:29.988342Z","shell.execute_reply.started":"2025-07-07T05:00:25.996568Z","shell.execute_reply":"2025-07-07T05:00:29.987584Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class COCODataset(Dataset):\n    def __init__(self, root, train, transform=None):\n        super().__init__()\n        directory = \"train\" if train else \"val\"\n        annotations = os.path.join(root, \"annotations\", f\"{directory}_annotations.json\")\n        self.coco = COCO(annotations)\n        self.image_path = os.path.join(root, directory)\n        self.transform = transform \n        self.categories = self.__get_categories()\n        self.data = self.__load_data()\n           \n    def __get_categories(self):\n        categories = {0 : 'background'}\n        for category in self.coco.cats.values():\n            categories[category['id']] = category['name']\n        return categories\n    \n    def __load_data(self):\n        data = []\n        for _id in self.coco.imgs:\n            file_name = self.coco.loadImgs(_id)[0]['file_name']\n            image_path = os.path.join(self.image_path, file_name)\n            image = Image.open(image_path).convert(\"RGB\")\n\n            boxes = []\n            labels = []\n            anns = self.coco.loadAnns(self.coco.getAnnIds(_id))\n\n            for ann in anns:\n                x, y, w, h = ann['bbox']\n                boxes.append([x, y, x+w, y+h])\n                labels.append(ann['category_id'])\n            target = {\n                'image_id' : torch.LongTensor([_id]),\n                'boxes' : torch.FloatTensor(boxes),\n                'labels' : torch.LongTensor(labels)\n            }\n            data.append([image, target])\n        return data\n       \n    \n    def __getitem__(self, index):\n        image, target = self.data[index]\n        if self.transform:\n            image =self.transform(image)\n        return image, target\n        \n    def __len__(self):\n        return len(self.data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:00:29.989101Z","iopub.execute_input":"2025-07-07T05:00:29.989393Z","iopub.status.idle":"2025-07-07T05:00:29.997527Z","shell.execute_reply.started":"2025-07-07T05:00:29.989375Z","shell.execute_reply":"2025-07-07T05:00:29.996488Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from torchvision import transforms\nfrom torch.utils.data import DataLoader\n\ndef collator(batch):\n    return tuple(zip(*batch))\n\ntransform = transforms.Compose([\n    transforms.PILToTensor(),\n    transforms.ConvertImageDtype(dtype=torch.float)\n])\nroot = \"/kaggle/input/pytorch-transformer/datasets/coco/\"\n\ntrain_dataset = COCODataset(root, train=True,transform=transform)\ntrain_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, drop_last = True, \n          collate_fn = collator)\n\ntest_dataset = COCODataset(root, train=False,transform=transform)\ntest_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last = True, \n          collate_fn = collator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:00:29.999291Z","iopub.execute_input":"2025-07-07T05:00:29.999766Z","iopub.status.idle":"2025-07-07T05:01:02.662031Z","shell.execute_reply.started":"2025-07-07T05:00:29.999741Z","shell.execute_reply":"2025-07-07T05:01:02.661235Z"}},"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=0.29s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.01s)\ncreating index...\nindex created!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from torchvision import models \nfrom torchvision import ops \nfrom torchvision.models.detection import rpn , FasterRCNN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:01:02.662885Z","iopub.execute_input":"2025-07-07T05:01:02.663174Z","iopub.status.idle":"2025-07-07T05:01:02.667105Z","shell.execute_reply.started":"2025-07-07T05:01:02.663157Z","shell.execute_reply":"2025-07-07T05:01:02.666274Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"backbone = models.vgg16(weights=\"VGG16_Weights.IMAGENET1K_V1\").features\nbackbone.out_channels = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:01:02.667920Z","iopub.execute_input":"2025-07-07T05:01:02.668149Z","iopub.status.idle":"2025-07-07T05:01:06.831947Z","shell.execute_reply.started":"2025-07-07T05:01:02.668134Z","shell.execute_reply":"2025-07-07T05:01:06.831351Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 223MB/s] \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"anchor_generator = rpn.AnchorGenerator(\n    sizes= ((32, 64, 128, 256, 512),),\n    aspect_ratios = ((0.5, 1.0, 2.0),)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:01:06.832645Z","iopub.execute_input":"2025-07-07T05:01:06.832891Z","iopub.status.idle":"2025-07-07T05:01:06.847958Z","shell.execute_reply.started":"2025-07-07T05:01:06.832873Z","shell.execute_reply":"2025-07-07T05:01:06.847427Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"roi_pooler = ops.MultiScaleRoIAlign(\n    featmap_names = [\"0\"],\n    output_size=(7,7),\n    sampling_ratio = 2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:01:06.848825Z","iopub.execute_input":"2025-07-07T05:01:06.849589Z","iopub.status.idle":"2025-07-07T05:01:06.869328Z","shell.execute_reply.started":"2025-07-07T05:01:06.849560Z","shell.execute_reply":"2025-07-07T05:01:06.868588Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:01:06.870087Z","iopub.execute_input":"2025-07-07T05:01:06.870321Z","iopub.status.idle":"2025-07-07T05:01:06.936936Z","shell.execute_reply.started":"2025-07-07T05:01:06.870303Z","shell.execute_reply":"2025-07-07T05:01:06.936201Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:01:06.939055Z","iopub.execute_input":"2025-07-07T05:01:06.939517Z","iopub.status.idle":"2025-07-07T05:01:06.953246Z","shell.execute_reply.started":"2025-07-07T05:01:06.939496Z","shell.execute_reply":"2025-07-07T05:01:06.952581Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"model = FasterRCNN(\n    backbone=backbone, \n    num_classes = 3,\n    rpn_anchor_generator = anchor_generator,\n    box_roi_pool  = roi_pooler\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:01:06.953880Z","iopub.execute_input":"2025-07-07T05:01:06.954070Z","iopub.status.idle":"2025-07-07T05:01:07.426358Z","shell.execute_reply.started":"2025-07-07T05:01:06.954055Z","shell.execute_reply":"2025-07-07T05:01:07.425822Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from torch import optim\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\nlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:01:07.427100Z","iopub.execute_input":"2025-07-07T05:01:07.427314Z","iopub.status.idle":"2025-07-07T05:01:07.432158Z","shell.execute_reply.started":"2025-07-07T05:01:07.427298Z","shell.execute_reply":"2025-07-07T05:01:07.431452Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"for epoch in range(5):\n    cost = 0.0\n    for idx, (images, targets)  in enumerate(train_dataloader):\n        #image = image.to(device)\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        loss_dict = model(images, targets)\n        losses = sum([loss for loss in loss_dict.values()])\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n        cost += losses \n    lr_scheduler.step()\n    cost = cost / len(train_dataloader)\n    print(f\"Epoch : {epoch + 1:4d}, Cost : {cost:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:01:07.432922Z","iopub.execute_input":"2025-07-07T05:01:07.433185Z","iopub.status.idle":"2025-07-07T05:09:36.147909Z","shell.execute_reply.started":"2025-07-07T05:01:07.433170Z","shell.execute_reply":"2025-07-07T05:09:36.146970Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3438396613.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#image = image.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/3438396613.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#image = image.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"loss_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:09:36.148383Z","iopub.status.idle":"2025-07-07T05:09:36.148586Z","shell.execute_reply.started":"2025-07-07T05:09:36.148487Z","shell.execute_reply":"2025-07-07T05:09:36.148496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom torchvision.transforms.functional import to_pil_image\n\n\ndef draw_bbox(ax, box, text, color):\n    ax.add_patch(\n        plt.Rectangle(\n            xy=(box[0], box[1]),\n            width=box[2] - box[0],\n            height=box[3] - box[1],\n            fill=False,\n            edgecolor=color,\n            linewidth=2,\n        )\n    )\n    ax.annotate(\n        text=text,\n        xy=(box[0] - 5, box[1] - 5),\n        color=color,\n        weight=\"bold\",\n        fontsize=13,\n    )\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:09:36.149766Z","iopub.status.idle":"2025-07-07T05:09:36.149984Z","shell.execute_reply.started":"2025-07-07T05:09:36.149886Z","shell.execute_reply":"2025-07-07T05:09:36.149895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"threshold = 0.5\ncategories = test_dataset.categories\nwith torch.no_grad():\n    model.eval()\n    for images, targets in test_dataloader:\n        images = [image.to(device) for image in images]\n        outputs = model(images)\n        \n        boxes = outputs[0][\"boxes\"].to(\"cpu\").numpy()\n        labels = outputs[0][\"labels\"].to(\"cpu\").numpy()\n        scores = outputs[0][\"scores\"].to(\"cpu\").numpy()\n        \n        boxes = boxes[scores >= threshold].astype(np.int32)\n        labels = labels[scores >= threshold]\n        scores = scores[scores >= threshold]\n\n        fig = plt.figure(figsize=(8, 8))\n        ax = fig.add_subplot(1, 1, 1)\n        plt.imshow(to_pil_image(images[0]))\n\n        for box, label, score in zip(boxes, labels, scores):\n            draw_bbox(ax, box, f\"{categories[label]} - {score:.4f}\", \"red\")\n\n        tboxes = targets[0][\"boxes\"].numpy()\n        tlabels = targets[0][\"labels\"].numpy()\n        for box, label in zip(tboxes, tlabels):\n            draw_bbox(ax, box, f\"{categories[label]}\", \"blue\")\n            \n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:09:36.151413Z","iopub.status.idle":"2025-07-07T05:09:36.151759Z","shell.execute_reply.started":"2025-07-07T05:09:36.151578Z","shell.execute_reply":"2025-07-07T05:09:36.151592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Image\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:09:42.840315Z","iopub.execute_input":"2025-07-07T05:09:42.840572Z","iopub.status.idle":"2025-07-07T05:09:42.844683Z","shell.execute_reply.started":"2025-07-07T05:09:42.840552Z","shell.execute_reply":"2025-07-07T05:09:42.844055Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_01.png', width=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:09:44.541978Z","iopub.execute_input":"2025-07-07T05:09:44.542468Z","iopub.status.idle":"2025-07-07T05:09:44.547269Z","shell.execute_reply.started":"2025-07-07T05:09:44.542445Z","shell.execute_reply":"2025-07-07T05:09:44.546746Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/html":"<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_01.png\" width=\"500\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_02.png', width=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:09:47.054300Z","iopub.execute_input":"2025-07-07T05:09:47.054848Z","iopub.status.idle":"2025-07-07T05:09:47.059740Z","shell.execute_reply.started":"2025-07-07T05:09:47.054821Z","shell.execute_reply":"2025-07-07T05:09:47.059019Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/html":"<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_02.png\" width=\"500\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_03.png', width=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:09:52.746164Z","iopub.execute_input":"2025-07-07T05:09:52.746428Z","iopub.status.idle":"2025-07-07T05:09:52.750960Z","shell.execute_reply.started":"2025-07-07T05:09:52.746400Z","shell.execute_reply":"2025-07-07T05:09:52.750275Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/html":"<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_03.png\" width=\"500\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_04.png', width=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:10:09.182368Z","iopub.execute_input":"2025-07-07T05:10:09.182635Z","iopub.status.idle":"2025-07-07T05:10:09.187452Z","shell.execute_reply.started":"2025-07-07T05:10:09.182617Z","shell.execute_reply":"2025-07-07T05:10:09.186890Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/html":"<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_04.png\" width=\"500\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_05.png', width=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:13:00.025169Z","iopub.execute_input":"2025-07-07T05:13:00.025774Z","iopub.status.idle":"2025-07-07T05:13:00.030642Z","shell.execute_reply.started":"2025-07-07T05:13:00.025752Z","shell.execute_reply":"2025-07-07T05:13:00.029968Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/html":"<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_05.png\" width=\"500\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:14:17.955757Z","iopub.execute_input":"2025-07-07T05:14:17.956484Z","iopub.status.idle":"2025-07-07T05:14:17.960131Z","shell.execute_reply.started":"2025-07-07T05:14:17.956456Z","shell.execute_reply":"2025-07-07T05:14:17.959342Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}