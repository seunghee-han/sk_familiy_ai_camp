{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02275336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello there! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C0iDQGxDvJ0BZbOqo6d9cKCEdK8LQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9208b8b6-92e6-44e2-a8c8-76f7b1641779-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "os.environ['LANGSMITH_PROJECT']  =\"skn15-1\"\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913d3ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skn15-1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LANGSMITH_PROJECT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead04a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "loader = CSVLoader(file_path=\"./아리계곡_통합.csv\")\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ecaeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(docs, embedding = embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab8bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "다음 문맥만을 고려해 질문에 답하세요.\n",
    "\n",
    "\n",
    "문맥: \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "질문: {question}\n",
    "''')\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "\n",
    "chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": retriever,\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "\n",
    "output = chain.invoke(\"가게 분위기는 어떤가?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f247a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('가게 분위기는 전반적으로 좋다고 평가되고 있습니다. 여러 리뷰에서 \"분위기 완전 좋고\", \"분위기도 좋고 깨끗해서\", \"분위기가 '\n",
      " '좋아요\", \"분위기도 좋고 음식도 매장 디자인도 괜찮고\"라는 긍정적인 언급이 있습니다. 따라서 가게의 분위기는 매우 긍정적으로 '\n",
      " '받아들여지고 있습니다.')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "\n",
    "pprint.pprint(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6c86bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skn15-1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LANGSMITH_PROJECT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d0836ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C0i9cevhzNaqrbH399kEgFtxdgNvd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--82cbf119-6337-47b9-be68-86f44b446aa2-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f41d133e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatPromptTemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mQueryGenerationOutput\u001b[39;00m(BaseModel):\n\u001b[32m      7\u001b[39m     queries: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] = Field(..., description=\u001b[33m\"\u001b[39m\u001b[33m검색 쿼리 목록\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m query_generation_prompt = \u001b[43mChatPromptTemplate\u001b[49m.from_template(\u001b[33m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33m질문에 대해 벡터 데이터베이스에서 관련 문서를 검색하기 위한\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m3개의 서로 다른 검색 쿼리를 생성하세요.\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m거리 기반 유사성 검색의 한계를 극복하기 위해\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m사용자의 질문에 대해 여러 관점을 제공하는 것이 목표입니다.\u001b[39m\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[33m질문: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     23\u001b[39m query_generation_chain = (\n\u001b[32m     24\u001b[39m     query_generation_prompt\n\u001b[32m     25\u001b[39m     | model.with_structured_output(QueryGenerationOutput)\n\u001b[32m     26\u001b[39m     | (\u001b[38;5;28;01mlambda\u001b[39;00m x: x.queries)\n\u001b[32m     27\u001b[39m )\n\u001b[32m     32\u001b[39m multi_query_rag_chain = {\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: RunnablePassthrough(),\n\u001b[32m     34\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: query_generation_chain | retriever.map(),\n\u001b[32m     35\u001b[39m } | prompt | model | StrOutputParser()\n",
      "\u001b[31mNameError\u001b[39m: name 'ChatPromptTemplate' is not defined"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class QueryGenerationOutput(BaseModel):\n",
    "    queries: list[str] = Field(..., description=\"검색 쿼리 목록\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "query_generation_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "질문에 대해 벡터 데이터베이스에서 관련 문서를 검색하기 위한\n",
    "3개의 서로 다른 검색 쿼리를 생성하세요.\n",
    "거리 기반 유사성 검색의 한계를 극복하기 위해\n",
    "사용자의 질문에 대해 여러 관점을 제공하는 것이 목표입니다.\n",
    "\n",
    "\n",
    "질문: {question}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "query_generation_chain = (\n",
    "    query_generation_prompt\n",
    "    | model.with_structured_output(QueryGenerationOutput)\n",
    "    | (lambda x: x.queries)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "multi_query_rag_chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": query_generation_chain | retriever.map(),\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "multi_query_rag_chain.invoke(\"주위사람에게 추천할 의사는?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbaf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion( retriever_outputs: list[list[Document]],  k: int = 60 ) -> list[str]:\n",
    "    # 각 문서의 콘텐츠(문자열)와 그 점수의 매핑을 저장하는 딕셔너리 준비\n",
    "    content_score_mapping = {}\n",
    "\n",
    "\n",
    "    # 검색 쿼리마다 반복\n",
    "    for docs in retriever_outputs:\n",
    "        # 검색 결과의 문서마다 반복\n",
    "        for rank, doc in enumerate(docs):\n",
    "            content = doc.page_content\n",
    "\n",
    "\n",
    "            # 처음 등장한 콘텐츠인 경우 점수를 0으로 초기화\n",
    "            if content not in content_score_mapping:\n",
    "                content_score_mapping[content] = 0\n",
    "\n",
    "\n",
    "            # (1 / (순위 + k)) 점수를 추가\n",
    "            content_score_mapping[content] += 1 / (rank + k)\n",
    "\n",
    "\n",
    "    # 점수가 큰 순서로 정렬\n",
    "    ranked = sorted(content_score_mapping.items(), key=lambda x: x[1], reverse=True)  # noqa\n",
    "    return [content for content, _ in ranked]\n",
    "\n",
    "\n",
    "rag_fusion_chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": query_generation_chain | retriever.map() | reciprocal_rank_fusion,\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "rag_fusion_chain.invoke(\"가게 분위기는?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5edd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "langchain_document_retriever = retriever.with_config({'run_name' : 'langchain_document_retriver'})\n",
    "web_retriever = TavilySearchAPIRetriever(k=10).with_config({'run_name' : 'web_retriver'})\n",
    "\n",
    "\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Route(str, Enum):\n",
    "    langchain_document = 'langchain_document'\n",
    "    web = \"web\"\n",
    "\n",
    "\n",
    "class RouteOutput(BaseModel):\n",
    "    route: Route\n",
    "\n",
    "\n",
    "route_prompt  =  ChatPromptTemplate.from_template(\"\"\"  \n",
    "질문에 답변하기 위한 적절한 Retriever를 선택하세요.\n",
    "\n",
    "\n",
    "질문: {question}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "route_chain = (\n",
    "    route_prompt | model.with_structured_output(RouteOutput)\n",
    "    | (lambda x : x.route)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def routed_retriever(inp):\n",
    "    question = inp['question']\n",
    "    route = inp['route']\n",
    "\n",
    "\n",
    "    if route == Route.langchain_document:\n",
    "        return langchain_document_retriever.invoke(question)\n",
    "    elif route == Route.web:\n",
    "        return web_retriever.invoke(question)\n",
    "\n",
    "\n",
    "    raise ValueError(f\"Unkown route: {route}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "route_rag_chain = ({\n",
    "    'question' : RunnablePassthrough(),\n",
    "    \"route\" : route_chain\n",
    "}\n",
    "| RunnablePassthrough.assign(context=routed_retriever)\n",
    "| prompt | model | StrOutputParser())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "route_rag_chain.invoke(\"아리계곡 마감 시간은?\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0026b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import re \n",
    "p = re.compile(\"'([0-9]+)'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_ticker(company):\n",
    "    text_url = \"https://dart.fss.or.kr/dsae001/search.ax\"\n",
    "    payload = {\n",
    "    \"startDate\": \"\",     \"endDate\": \"\",\n",
    "    \"currentPage\": 1,     \"maxResults\": 45,\n",
    "    \"maxLinks\": 10,     \"sort\": \"\",\n",
    "    \"series\": \"\",     \"selectKey\": \"\",\n",
    "    \"searchIndex\": \"\",     \"textCrpCik\": \"\",\n",
    "    \"autoSearch\": True,     \"businessCode\": \"all\",\n",
    "    \"bsnRgsNo\": \"\",     \"bsnRgsNo_1\": \"\",\n",
    "    \"bsnRgsNo_2\": \"\",     \"bsnRgsNo_3\": \"\",\n",
    "    \"crpRgsNo\": \"\",     \"textCrpNm\": company,\n",
    "    \"corporationType\": \"all\"\n",
    "    }\n",
    "    r = requests.post(text_url, data=payload)\n",
    "    bs = BeautifulSoup(r.text)\n",
    "    result = {x.text.strip():p.findall(x['href'])[0] for x in bs.find_all('a')[:-1]}\n",
    "    return result[company]\n",
    "\n",
    "\n",
    "get_ticker(\"삼성전자\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8638894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statement(company, company_code, start_date, end_date):\n",
    "    data = {\n",
    "    \"currentPage\": 1,     \"maxResults\": 15,\n",
    "    \"maxLinks\": 10,     \"sort\": \"date\",\n",
    "    \"series\": \"desc\",     \"textCrpCik\": company_code,\n",
    "    \"lateKeyword\": \"\",    \"keyword\": \"\",     \"reportNamePopYn\": \"\",\n",
    "    \"textkeyword\": \"\",     \"businessCode\": \"all\",     \"autoSearch\": \"N\",\n",
    "    \"option\": \"corp\",\n",
    "    \"textCrpNm\": company,\n",
    "    \"reportName\": \"\",    \"tocSrch\": \"\",\n",
    "    \"textPresenterNm\": \"\",\n",
    "    \"startDate\": start_date,\n",
    "    \"endDate\":  end_date,\n",
    "    \"decadeType\": \"\",    \"finalReport\": \"recent\",    \"businessNm\": \"전체\",\n",
    "    \"corporationType\": \"all\",    \"closingAccountsMonth\": \"all\",\n",
    "    \"reportName2\": \"\",    \"tocSrch2\": \"\",\n",
    "    \"publicType\": [\n",
    "        \"A001\", \"A002\", \"A003\", \"A005\", \"A004\",\n",
    "        \"B001\", \"B002\", \"B003\",\n",
    "        \"C001\", \"C002\", \"C003\", \"C004\", \"C005\", \"C006\", \"C007\", \"C008\", \"C009\", \"C010\", \"C011\",\n",
    "        \"D001\", \"D004\", \"D003\", \"D002\", \"D005\",\n",
    "        \"E001\", \"E002\", \"E003\", \"E004\", \"E005\", \"E006\", \"E007\", \"E008\", \"E009\",\n",
    "        \"F001\", \"F002\", \"F003\", \"F004\", \"F005\",\n",
    "        \"G001\", \"G002\", \"G003\",\n",
    "        \"H001\", \"H002\", \"H003\", \"H004\", \"H005\", \"H006\"\n",
    "        ]\n",
    "    }\n",
    "    url = \"https://dart.fss.or.kr/dsab007/detailSearch.ax\"\n",
    "    return requests.post(url, data=data).text\n",
    "\n",
    "\n",
    "\n",
    "rt = get_statement(\"삼성전자\", \"00126380\", \"20240101\" , '20250731')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9dc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "class GetStatementInput(BaseModel):\n",
    "    company: str = Field(..., description='회사 이름')\n",
    "    company_code: str = Field(..., description='회사 코드')\n",
    "    start_date: str = Field(..., description=\"YYYYMMDD 형식의 시작 날짜\")\n",
    "    end_date: str = Field(..., description=\"YYYYMMDD 형식의 종료 날짜\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from typing import Optional, Type\n",
    "class GetStatementTool(BaseTool):\n",
    "    name: str = 'GetStatementTool'            \n",
    "    description: str = '기업의 공시 자료를 가져옵니다.'\n",
    "   \n",
    "    args_schema: Type[BaseModel] = GetStatementInput\n",
    "\n",
    "\n",
    "    def _run(self, company, company_code, start_date, end_date):\n",
    "        return get_statement(company=company, company_code=company_code, start_date=start_date, end_date=end_date)\n",
    "\n",
    "class GetTickerTool(BaseTool):\n",
    "    name: str = 'GetTickerTool'                \n",
    "    description: str = 'Dart에서 사용하는 기업의 code 리턴 '\n",
    "\n",
    "\n",
    "    def _run(self, company):\n",
    "        return get_ticker(company=company)\n",
    "\n",
    "\n",
    "tools = [GetTickerTool(), GetStatementTool()]\n",
    "chat = ChatOpenAI(model = 'gpt-4o-2024-08-06')\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    chat,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "result = agent.run(\"당신은 지금부터 애널리스트입니다. LG전자의 20240101부터 20241231까지 공시 정보를 활용해서 분석 리포트를 자세히 작성할 것. 그리고 투자 의견에 대한 내용도 결론에 넣을 것\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175d26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e55ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce6dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cba687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
