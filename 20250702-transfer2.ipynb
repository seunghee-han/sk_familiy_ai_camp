{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T03:10:30.730528Z","iopub.execute_input":"2025-07-02T03:10:30.730790Z","iopub.status.idle":"2025-07-02T03:10:32.961749Z","shell.execute_reply.started":"2025-07-02T03:10:30.730764Z","shell.execute_reply":"2025-07-02T03:10:32.960882Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\nelse:\n    DEVICE = torch.device('cpu')\nprint('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, models, transforms\nimport time\nimport os\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=data_transforms['train'])\nval_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=data_transforms['val'])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nclass_names = train_dataset.classes\n\n\nmodel_transfer = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n\nfrom IPython.display import Image\nImage(\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\")\n\n\n# for param in model_transfer.features.parameters():\n#     #print(param.shape)\n#     param.requires_grad = False\n\nmodel_transfer.classifier[6] = nn.Linear(model_transfer.classifier[6].in_features, len(class_names))\n\n\nmodel_transfer = model_transfer.to(DEVICE)\noptimizer  = optim.Adam(model_transfer.classifier.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\nfor param in model_transfer.features.parameters():\n    print(param.requires_grad)\n\n\nfor param in model_transfer.classifier.parameters():\n    print(param.requires_grad)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T03:11:23.406295Z","iopub.execute_input":"2025-07-02T03:11:23.407037Z","iopub.status.idle":"2025-07-02T03:11:43.071214Z","shell.execute_reply.started":"2025-07-02T03:11:23.407008Z","shell.execute_reply":"2025-07-02T03:11:43.070408Z"}},"outputs":[{"name":"stdout","text":"Using PyTorch version: 2.6.0+cu124  Device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:02<00:00, 83.1MB/s] \nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 191MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from torchinfo import summary\nsummary(model_transfer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T03:12:08.596750Z","iopub.execute_input":"2025-07-02T03:12:08.597141Z","iopub.status.idle":"2025-07-02T03:12:08.626561Z","shell.execute_reply.started":"2025-07-02T03:12:08.597114Z","shell.execute_reply":"2025-07-02T03:12:08.625734Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nVGG                                      --\n├─Sequential: 1-1                        --\n│    └─Conv2d: 2-1                       1,792\n│    └─ReLU: 2-2                         --\n│    └─Conv2d: 2-3                       36,928\n│    └─ReLU: 2-4                         --\n│    └─MaxPool2d: 2-5                    --\n│    └─Conv2d: 2-6                       73,856\n│    └─ReLU: 2-7                         --\n│    └─Conv2d: 2-8                       147,584\n│    └─ReLU: 2-9                         --\n│    └─MaxPool2d: 2-10                   --\n│    └─Conv2d: 2-11                      295,168\n│    └─ReLU: 2-12                        --\n│    └─Conv2d: 2-13                      590,080\n│    └─ReLU: 2-14                        --\n│    └─Conv2d: 2-15                      590,080\n│    └─ReLU: 2-16                        --\n│    └─MaxPool2d: 2-17                   --\n│    └─Conv2d: 2-18                      1,180,160\n│    └─ReLU: 2-19                        --\n│    └─Conv2d: 2-20                      2,359,808\n│    └─ReLU: 2-21                        --\n│    └─Conv2d: 2-22                      2,359,808\n│    └─ReLU: 2-23                        --\n│    └─MaxPool2d: 2-24                   --\n│    └─Conv2d: 2-25                      2,359,808\n│    └─ReLU: 2-26                        --\n│    └─Conv2d: 2-27                      2,359,808\n│    └─ReLU: 2-28                        --\n│    └─Conv2d: 2-29                      2,359,808\n│    └─ReLU: 2-30                        --\n│    └─MaxPool2d: 2-31                   --\n├─AdaptiveAvgPool2d: 1-2                 --\n├─Sequential: 1-3                        --\n│    └─Linear: 2-32                      102,764,544\n│    └─ReLU: 2-33                        --\n│    └─Dropout: 2-34                     --\n│    └─Linear: 2-35                      16,781,312\n│    └─ReLU: 2-36                        --\n│    └─Dropout: 2-37                     --\n│    └─Linear: 2-38                      40,970\n=================================================================\nTotal params: 134,301,514\nTrainable params: 134,301,514\nNon-trainable params: 0\n================================================================="},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"BATCH_SIZE = 32\n\ndef train(model, train_loader, optimizer, log_interval):\n    global output, label\n    model.train()\n    correct = 0\n    train_loss = 0\n    for batch_idx, (image, label) in enumerate(train_loader):\n        image = image.to(DEVICE)\n        label = label.to(DEVICE)\n        optimizer.zero_grad()\n        output = model(image)\n        loss = criterion(output, label)\n        train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n\n\n        _, prediction = torch.max(output, dim=1 )\n        # 정답을 맞춘 갯수\n        # acc += sum(idx == label)\n        correct += prediction.eq(label.view_as(prediction)).sum().item()\n\n\n        if batch_idx % log_interval == 0:\n            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n                epoch, batch_idx * len(image),\n                len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n                loss.item()))\n           \n    train_loss /= (len(train_loader.dataset) / BATCH_SIZE)\n    train_accuracy = 100. * correct / len(train_loader.dataset)\n\n\n    return train_loss, train_accuracy\n\n\n\ndef evaluate(model, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n\n    with torch.no_grad():\n        for image, label in test_loader:\n            image = image.to(DEVICE)\n            label = label.to(DEVICE)\n            output = model(image)\n            test_loss += criterion(output, label).item()\n            prediction = output.max(1, keepdim = True)[1]\n            correct += prediction.eq(label.view_as(prediction)).sum().item()\n\n\n    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n    test_accuracy = 100. * correct / len(test_loader.dataset)\n    return test_loss, test_accuracy\n\nEPOCHS = 5\nloss_hist_train     = [0] * EPOCHS\naccuracy_hist_train = [0] * EPOCHS\nloss_hist_valid     = [0] * EPOCHS\naccuracy_hist_valid = [0] * EPOCHS\n\nfor epoch in range(1, EPOCHS + 1):\n    loss_, acc_ = train(model_transfer, train_loader, optimizer, log_interval = 200)\n    loss_hist_train[epoch] = loss_\n    accuracy_hist_train[epoch] = acc_\n    test_loss, test_accuracy = evaluate(model_transfer, val_loader)\n    loss_hist_valid[epoch] = test_loss\n    accuracy_hist_valid[epoch] = test_accuracy\n    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n        epoch, test_loss, test_accuracy))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T03:12:17.760713Z","iopub.execute_input":"2025-07-02T03:12:17.761034Z"}},"outputs":[{"name":"stdout","text":"Train Epoch: 1 [0/50000 (0%)]\tTrain Loss: 2.501790\nTrain Epoch: 1 [6400/50000 (13%)]\tTrain Loss: 0.905717\nTrain Epoch: 1 [12800/50000 (26%)]\tTrain Loss: 0.791066\nTrain Epoch: 1 [19200/50000 (38%)]\tTrain Loss: 0.677942\nTrain Epoch: 1 [25600/50000 (51%)]\tTrain Loss: 1.077359\nTrain Epoch: 1 [32000/50000 (64%)]\tTrain Loss: 1.194925\nTrain Epoch: 1 [38400/50000 (77%)]\tTrain Loss: 0.555558\nTrain Epoch: 1 [44800/50000 (90%)]\tTrain Loss: 0.722624\n\n[EPOCH: 1], \tTest Loss: 0.5032, \tTest Accuracy: 84.44 % \n\nTrain Epoch: 2 [0/50000 (0%)]\tTrain Loss: 0.522824\n","output_type":"stream"}],"execution_count":null}]}