{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:30:06.730431Z","iopub.execute_input":"2025-07-22T03:30:06.731041Z","iopub.status.idle":"2025-07-22T03:31:29.227457Z","shell.execute_reply.started":"2025-07-22T03:30:06.731002Z","shell.execute_reply":"2025-07-22T03:31:29.226632Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import transformers\nimport datasets\nimport accelerate\nimport peft\nimport bitsandbytes\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:35:14.660893Z","iopub.execute_input":"2025-07-22T03:35:14.661154Z","iopub.status.idle":"2025-07-22T03:35:49.085365Z","shell.execute_reply.started":"2025-07-22T03:35:14.661132Z","shell.execute_reply":"2025-07-22T03:35:49.084555Z"}},"outputs":[{"name":"stderr","text":"2025-07-22 03:35:32.434123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753155332.806658      91 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753155332.909329      91 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:35:49.086565Z","iopub.execute_input":"2025-07-22T03:35:49.087154Z","iopub.status.idle":"2025-07-22T03:35:49.091050Z","shell.execute_reply.started":"2025-07-22T03:35:49.087133Z","shell.execute_reply":"2025-07-22T03:35:49.090336Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def print_gpu_utilization():\n    if torch.cuda.is_available():\n        used_memory = torch.cuda.memory_allocated() / 1024**3\n        print(f\"GPU 메모리 사용량: {used_memory:.3f} GB\")\n    else:\n        print(\"런타임 유형을 GPU로 변경하세요\")\n\nprint_gpu_utilization()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:36:18.837316Z","iopub.execute_input":"2025-07-22T03:36:18.837625Z","iopub.status.idle":"2025-07-22T03:36:18.842858Z","shell.execute_reply.started":"2025-07-22T03:36:18.837606Z","shell.execute_reply":"2025-07-22T03:36:18.842264Z"}},"outputs":[{"name":"stdout","text":"GPU 메모리 사용량: 0.000 GB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\ndef load_model_and_tokenizer(model_id, peft=None):\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n    if peft is None:\n        model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=\"auto\", device_map={\"\":0})\n\n    print_gpu_utilization()\n    return model, tokenizer\n\nmodel_id = \"EleutherAI/polyglot-ko-1.3b\"\nmodel, tokenizer = load_model_and_tokenizer(model_id) # GPU 메모리 사용량: 2.599 GB\nprint(\"모델 파라미터 데이터 타입: \", model.dtype) # torch.float16\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:36:21.692214Z","iopub.execute_input":"2025-07-22T03:36:21.692514Z","iopub.status.idle":"2025-07-22T03:36:33.825147Z","shell.execute_reply.started":"2025-07-22T03:36:21.692493Z","shell.execute_reply":"2025-07-22T03:36:33.824380Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/164 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b93793f309a442495dc3e8246830f56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1551111e5bde4f97b97ecbb455420c88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/185 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbcaa1ed109143d58d33e3048276957b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/640 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcd88c5fc31945c3948ab3ed33c0bcbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c0e4570382449ce92731595419d7c2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb65c9e413d348cf844a5f0cd08d2e86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/748M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b94e2b5e643415a812d9071fd98ade4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dc357f8bed34ee69a8f69b59e8141fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/1.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"458c5402a60941ac8ba49c0664a900d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"290cf4330f0c41ec9b36dde1bfdf87b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9811d6478914672a2d33846c22e22c9"}},"metadata":{}},{"name":"stdout","text":"GPU 메모리 사용량: 2.481 GB\n모델 파라미터 데이터 타입:  torch.float16\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from bitsandbytes.optim  import AdamW\nfrom torch.utils.data import DataLoader\n\ndef estimate_memory_of_gradients(model):\n    total_memory = 0\n    for param in model.parameters():\n        if param.grad is not None:\n            total_memory += param.grad.nelement() * param.grad.element_size()\n    return total_memory\n\ndef estimate_memory_of_optimizer(optimizer):\n    total_memory = 0\n    for state in optimizer.state.values():\n        for k, v in state.items():\n            if torch.is_tensor(v):\n                total_memory += v.nelement() * v.element_size()\n    return total_memory","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:38:11.872108Z","iopub.execute_input":"2025-07-22T03:38:11.872804Z","iopub.status.idle":"2025-07-22T03:38:11.877732Z","shell.execute_reply.started":"2025-07-22T03:38:11.872778Z","shell.execute_reply":"2025-07-22T03:38:11.876945Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def train_model(model, dataset, training_args):\n    if training_args.gradient_checkpointing:\n        model.gradient_checkpointing_enable()\n\n    train_dataloader = DataLoader(dataset, batch_size=training_args.per_device_train_batch_size)\n    optimizer = AdamW(model.parameters())\n    model.train()\n    gpu_utilization_printed = False\n    for step, batch in enumerate(train_dataloader, start=1):\n        batch = {k: v.to(model.device) for k, v in batch.items()}\n\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss = loss / training_args.gradient_accumulation_steps\n        loss.backward()\n\n        if step % training_args.gradient_accumulation_steps == 0:\n            optimizer.step()\n            gradients_memory = estimate_memory_of_gradients(model)\n            optimizer_memory = estimate_memory_of_optimizer(optimizer)\n            if not gpu_utilization_printed:\n                print_gpu_utilization()\n                gpu_utilization_printed = True\n            optimizer.zero_grad()\n\n    print(f\"옵티마이저 상태의 메모리 사용량: {optimizer_memory / (1024 ** 3):.3f} GB\")\n    print(f\"그레디언트 메모리 사용량: {gradients_memory / (1024 ** 3):.3f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:38:18.876314Z","iopub.execute_input":"2025-07-22T03:38:18.876982Z","iopub.status.idle":"2025-07-22T03:38:18.882655Z","shell.execute_reply.started":"2025-07-22T03:38:18.876957Z","shell.execute_reply":"2025-07-22T03:38:18.882004Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nfrom datasets import Dataset\n\ndef make_dummy_dataset():\n  seq_len, dataset_size = 256, 64\n  dummy_data = {\n      \"input_ids\": np.random.randint(100, 30000, (dataset_size, seq_len)),\n      \"labels\": np.random.randint(100, 30000, (dataset_size, seq_len)),\n  }\n  dataset = Dataset.from_dict(dummy_data)\n  dataset.set_format(\"pt\")\n  return dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:38:24.436969Z","iopub.execute_input":"2025-07-22T03:38:24.437728Z","iopub.status.idle":"2025-07-22T03:38:24.442590Z","shell.execute_reply.started":"2025-07-22T03:38:24.437698Z","shell.execute_reply":"2025-07-22T03:38:24.441756Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import gc\n\ndef cleanup():\n    if 'model' in globals():\n        del globals()['model']\n    if 'dataset' in globals():\n        del globals()['dataset']\n    gc.collect()\n    torch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:38:28.514073Z","iopub.execute_input":"2025-07-22T03:38:28.514630Z","iopub.status.idle":"2025-07-22T03:38:28.518942Z","shell.execute_reply.started":"2025-07-22T03:38:28.514603Z","shell.execute_reply":"2025-07-22T03:38:28.518087Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ndef gpu_memory_experiment(batch_size,\n                          gradient_accumulation_steps=1,\n                          gradient_checkpointing=False,\n                          model_id=\"EleutherAI/polyglot-ko-1.3b\",\n                          peft=None):\n\n    print(f\"배치 사이즈: {batch_size}\")\n    model, tokenizer = load_model_and_tokenizer(model_id, peft=peft)\n    if gradient_checkpointing == True or peft == 'qlora':\n        model.config.use_cache = False\n\n    dataset = make_dummy_dataset()\n\n    training_args = TrainingArguments(\n        per_device_train_batch_size=batch_size,\n        gradient_accumulation_steps=gradient_accumulation_steps,\n        gradient_checkpointing=gradient_checkpointing,\n        output_dir=\"./result\",\n        num_train_epochs=1\n      )\n\n    try:\n        train_model(model, dataset, training_args)\n    except RuntimeError as e:\n        if \"CUDA out of memory\" in str(e):\n            print(e)\n        else:\n            raise e\n    finally:\n        del model, dataset\n        gc.collect()\n        torch.cuda.empty_cache()\n        print_gpu_utilization()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:38:36.230115Z","iopub.execute_input":"2025-07-22T03:38:36.230430Z","iopub.status.idle":"2025-07-22T03:38:38.321851Z","shell.execute_reply.started":"2025-07-22T03:38:36.230396Z","shell.execute_reply":"2025-07-22T03:38:38.321231Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"ㄴ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}