{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5f7aa3-4f71-46d1-8ec7-c9d3fab157e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def cleanup():\n",
    "    if 'model' in globals():\n",
    "        del globals()['model']\n",
    "    if 'dataset' in globals():\n",
    "        del globals()['dataset']\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece08107-44e6-4046-8eee-1d5877a1ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cfa60d6-ef59-4734-9b5e-0e0b602df042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef5732a-e705-4922-8c8d-916de30052d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_id, peft=None):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    if peft is None:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map={\"\":0})\n",
    "\n",
    "    elif peft == 'lora':\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16,  device_map={\"\":0})\n",
    "        lora_config = LoraConfig(\n",
    "                    r=8,\n",
    "                    lora_alpha=32,\n",
    "                    target_modules=[\n",
    "                                        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                                        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "                                    ],\n",
    "                    lora_dropout=0.05,\n",
    "                    bias=\"none\",\n",
    "                    task_type=\"CAUSAL_LM\"\n",
    "                )\n",
    "\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        model.print_trainable_parameters()\n",
    "\n",
    "    print_gpu_utilization()\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "582faefc-81fc-4b45-afc7-4a518f116375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def print_gpu_utilization():\n",
    "    if torch.cuda.is_available():\n",
    "        used_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        print(f\"GPU 메모리 사용량: {used_memory:.3f} GB\")\n",
    "    else:\n",
    "        print(\"런타임 유형을 GPU로 변경하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a35be251-6f33-4c69-8f48-671d9812b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Bllossom/llama-3.2-Korean-Bllossom-AICA-5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c37c1d4-63d7-4613-9ce2-af781452684b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0775cefe23924b0e815a57a8066dc032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496817a1231a435fb0104a2266f7f68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddae51998a5407099daaaa561719622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/835M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2901aab1e6084056adfa60bd3754e233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e1bcee649f428caffc6bf2d125f999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4a147fe68d4e958881d9c136df34cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab33304a89514062ae52071e853fdfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 15,196,160 || all params: 4,326,660,878 || trainable%: 0.3512\n",
      "GPU 메모리 사용량: 8.088 GB\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(model_id, peft='lora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312bba6a-355b-48bd-a775-05acbff76abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [128000, 102612, 114784, 121520, 123151, 105807], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"심장이 매우 뛰어요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc41ada2-eb47-4734-bbef-306208a2486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 15196160\n",
      "all params: 4326660878\n",
      "trainable%: 0.3512214252165848\n"
     ]
    }
   ],
   "source": [
    "trainable_params = 0\n",
    "all_param = 0\n",
    "for _, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if param.requires_grad:\n",
    "        trainable_params += param.numel()\n",
    "\n",
    "print(f\"\"\"trainable params: {trainable_params}\n",
    "all params: {all_param}\n",
    "trainable%: {100 * trainable_params / all_param}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3289d0af-baf9-4198-b944-023b3523822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf1fd00-045b-451c-963f-12fc4ce89d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a894facb2bb4f1ba356253a6e981ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"csv\", data_files={\"train\" : \"./train_data.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38e9a1e-63b1-4c3e-8dae-716bedf29550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ad96a0089d4eb6b5a5ed2f9735d924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12228 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2 = data.map(lambda x : {'text' : f\"\"\"User: {x['question']} \n",
    "                    Assistant: {x['answer']}<|endoftext|>\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df8faa74-0d8c-4257-9074-707cf0c83649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 10세 소년이 충치 치료를 위해 치과에 방문했다. 치과의사는 수복 재료로 아말감 대신 복합 레진을 권장하고 있다. 복합 레진 사용의 장점으로 가장 적절한 것은?  \n",
      "1) 심미성이 좋다.  \n",
      "2) 수복물의 강도가 높다.  \n",
      "3) 수은 함유로 인한 독성 위험이 있다.  \n",
      "4) 비용이 저렴하다.  \n",
      "5) 이차 우식증 발생 위험이 낮다. \n",
      "                    Assistant: 1) 심미성이 좋다.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for x in data2['train']:\n",
    "    print(x['text'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc9ded74-91cd-4153-9cbb-90503f8c7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9accc1b-f019-479b-8037-8c9686bb3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "argu = TrainingArguments(\n",
    "         per_device_train_batch_size=1,\n",
    "        num_train_epochs=2, \n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate = 0.0001,\n",
    "        fp16=True,\n",
    "        output_dir=\"./output/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62725abe-8e76-4845-b63b-7bd0f9721b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3b1fa213324c9180ed03c4c9206164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12228 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = data2.map(lambda samples: tokenizer(samples[\"text\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "703aefc7-44b4-48dc-bacb-3809ced737a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb17cae-68f3-4f99-b9d6-c74bbe962dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    train_dataset=train_dataset['train'],\n",
    "    args=argu,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3137510d-542a-4a1c-8828-7e5c601b4379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6114' max='6114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6114/6114 1:29:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.401300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.245600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.211600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.183300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.988100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.973900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.960900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.949000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6114, training_loss=1.0923873532001669, metrics={'train_runtime': 5366.4132, 'train_samples_per_second': 4.557, 'train_steps_per_second': 1.139, 'total_flos': 9.5783623801107e+16, 'train_loss': 1.0923873532001669, 'epoch': 2.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c10aab-cb33-40be-a8c0-54eca3e869e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
